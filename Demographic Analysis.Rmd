---
title: "Trajectories"
author: "Zachary"
date: '2025-07-28'
output: html_document
---

  
# Library & Notes
```{r setup, include=FALSE}
  ## â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ## ðŸ“¦ Data Import & Manipulation
  ## â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  library(haven)       # Read SPSS, SAS, Stata files
  library(readr)       # Read CSVs
  library(readxl)      # Read Excel files
  library(data.table)  # Fast data manipulation
  library(dplyr)       # Data manipulation
  library(tidyr)       # Data tidying
  library(stringr)     # String operations
  library(purrr)       # Functional programming
  library(zoo)         # Time series & rolling functions
  library(lubridate)   # Dates & times
  library(fuzzyjoin)   # Fuzzy matching joins
  
  ## â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ## ðŸ“Š Modeling & Statistics
  ## â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  library(lme4)        # Mixed-effects models
  library(lmerTest)    # p-values for lmer
  library(coxme)       # Cox mixed-effects models
  library(survival)    # Survival analysis
  library(MuMIn)       # Model selection & RÂ²
  library(lsmeans)     # Least-squares means (now emmeans)
  library(mgcv)        # Generalized Additive Models
  library(gratia)      # GAM diagnostics & visualization
  library(gamm4)       # GAMM fitting
  
  ## â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ## ðŸ“‘ Tables & Reporting
  ## â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  library(broom)       # Tidy model output
  library(pander)      # Pretty markdown tables
  library(apaTables)   # APA-style tables
  library(flextable)   # Formatted tables
  library(officer)     # Export to Word/PowerPoint
  library(webshot2)    # Save HTML tables/images
  
  ## â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ## ðŸŽ¨ Plotting & Visualization
  ## â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  library(ggplot2)     # General plotting
```

#Merge Datasets
```{r}
# setwd("C:/Users/hubshmz/Documents/Code/git/data")  # FORBOW computer
  setwd("C:/Users/zacha/OneDrive/Documents/Code/Data")  # Laptop
# setwd("C:/Users/zacha/Documents/RStudio/forbow/git/Data") # Tupper Windows Comp
# setwd("C:/Users/zacha/Documents/forbow/code/git/data") # Home Computer\




FOR <- readr::read_csv("analytic-zach1.csv", col_types = cols(.default = col_character()))
Night <- readr::read_csv("part4_nightsummary_sleep_cleaned.csv", col_types = cols(.default = col_character()))
NightM <- read_excel("motionloggerdata.xlsx")

#Fix clerical errors

Night$calendar_date <- as.Date(Night$calendar_date)
Night <- Night %>%
  mutate(
    calendar_date = case_when(
      filename == "800-0250-464_left wrist_068218_2025-12-01 14-08-11.bin" ~ calendar_date + 120,
      TRUE ~ calendar_date
    )
  )
Night$filename <- gsub("^800-304", "800-0304", Night$filename)
Night$filename <- gsub("^800-0066-106", "800-0065-106", Night$filename) # double check
Night$filename <- gsub("^800-0298-507", "800-0298-570", Night$filename)
Night$filename <- gsub("^800-0221-441", "800-0221-411", Night$filename)
Night$filename <- gsub("^0037062", "800-0037-062", Night$filename)

Night$Subject_ID <- substr(Night$filename, 1, 12)
Night <- Night %>%
  dplyr::rename(Assessment_Date = calendar_date)
Night <- Night %>% 
  filter(!str_detect(filename, "F[1-3]|f[1-3]|M[1-3]|m[1-3]|\\$R"))

##Filtering bad extraction. Filtering a weird GGIR duplication?     
bin_files_to_remove <- c(
  "8000156273_left wrist_060381_2024-11-05 12-04-08_partial.bin"
)
Night <- Night %>%
  filter(!filename %in% bin_files_to_remove)
Night <- Night %>%
  filter(
    !(filename == "800-0250-464_left wrist_068218_2025-12-01 14-08-11.bin" &
    sleepparam == "spt_crude_estimate")
  )


Night <- Night %>%
  mutate(Subject_ID = gsub("^800-(\\d{3})-(\\d+)_$", "800-0\\1-\\2", Subject_ID))
Night$Subject_ID <- gsub("-", "", Night$Subject_ID)
Night$Subject_ID <- gsub("[a-zA-Z]", "", Night$Subject_ID)
Night$Subject_ID <- gsub("_", "", Night$Subject_ID)
FOR$Subject_ID <- gsub("-", "", as.character(FOR$subject_id))
setDT(Night)
setDT(FOR)

##GeneACTIV Merging
Night$geneactiv <- 1
FOR[, Assessment_Date := as.Date(assessment_date)]
FOR$Assessment_Date_FOR <- FOR$Assessment_Date
Night[, Assessment_Date := as.Date(Assessment_Date)]  # redundant if already Date
Night$Assessment_Date_Night <- Night$Assessment_Date
merged1 <- Night[FOR, on = .(Subject_ID), allow.cartesian = TRUE]
merged1[, diffdays := (as.numeric(difftime(Assessment_Date_Night, Assessment_Date_FOR, units = "days")))]

merged1 <- merged1 %>% filter(diffdays >= 0 & diffdays <= 100)

two <- merged1[(Subject_ID %in% c(8000038204, 8000114479))]

##Motion Logger Merging
NightM <- NightM %>%
  mutate(filename = paste0(ID, "motionlogg"))
NightM$weekday <- NightM$eday
NightM <- NightM %>% 
  filter(!str_detect(Subject_ID, "F[1-3]|f[1-3]|M[1-3]|m[1-3]|\\$R"))
setDT(NightM)
NightM[, Assessment_Date := as.Date(sdate)]
NightM$Assessment_date_nightM <- NightM$Assessment_Date
NightM$Assessment_Date_Night <- NightM$Assessment_Date
merged2 <- NightM[FOR, on = .(Subject_ID), allow.cartesian = TRUE]
merged2[, diffdays := abs(as.numeric(difftime(Assessment_date_nightM, Assessment_Date_FOR, units = "days")))]
merged2 <- merged2 %>% filter(diffdays >= 0 & diffdays <= 100)
merged2$motionlogger <- 1

#Combination of Motion and GeneActiv
merged <- rbindlist(list(merged1, merged2), fill = TRUE)

merged$weekend <- ifelse(merged$weekday %in% c("Fri", "Friday", "Sat", "Saturday"), 1, 0)
merged$weekend <- factor(merged$weekend,
                         levels = c(0, 1),
                         labels = c("Weekday", "Weekend"))
merged <- merged %>%
  group_by(filename) %>%   # or filename
  filter(
    sum(weekend == "Weekend", na.rm = TRUE) >= 1,
    sum(weekend == "Weekday", na.rm = TRUE) >= 3
  ) %>%
  ungroup()
merged$group1 <- merged$group
merged$group <- factor(merged$group,
                       levels = c(0, 1, 2, 3),
                       labels = c("Control", "MDD Risk", "BD Risk", "Psy Risk"))

```

#Non Participators 
```{r}
#Length
FOR <- FOR %>% filter(!str_detect(subject_id, "F[1-3]|f[1-3]|M[1-3]|m[1-3]|\\$R"))
FOR <- FOR %>%filter(!str_detect(subject_id, "8009999123"))
length(unique(FOR$subject_id))

#Participators
merged <- merged %>%
  filter(group != "Psy Risk")
merged$age <- as.numeric(merged$age)
merged <- merged %>% filter(age < 25 & age >= 8)

#List of Non Sleep Participators Ever
list <- unique(merged$Subject_ID)
unmerged <- FOR[!Subject_ID %in% list]
unique(unmerged$Subject_ID)
unmerged <- unmerged %>%
  filter(!is.na(redcap_repeat_instance))
unmerged <- unmerged %>%
  filter(group != 3)
unmerged$age <- as.numeric(unmerged$age)
unmerged$group <- factor(unmerged$group,
                       levels = c(0, 1, 2, 3),
                       labels = c("Control", "MDD Risk", "BD Risk", "Psy Risk"))
unmerged <- unmerged %>% filter(age < 25 & age >= 8)
unmerged <- unmerged %>%
  group_by(Subject_ID) %>%
  slice(n()) %>%   # second-to-last row per Subject_ID
  ungroup()

table(unmerged$group)




merged <- merged %>%
    group_by(Subject_ID) %>%
    slice_tail(n = 1) %>%
  ungroup()
table(merged$group)
table(merged$sex)

#Amount of participants who made it into merged study
##268
table(merged$group)
table(merged$sex)

#Nonparticipants not participant

#280

#Filter assessment dates
unmerged <- unmerged %>%
  filter(Assessment_Date > as.Date("2021-07-01"))
table(unmerged$age)

#166

#Compare now
#sex
u_sex <- unmerged %>%
  transmute(sex, dataset = "unmerged")

m_sex <- merged %>%
  transmute(sex, dataset = "merged")

sex_compare <- bind_rows(u_sex, m_sex) %>%
  mutate(dataset = factor(dataset, levels = c("unmerged", "merged")))

sex_tab <- table(sex_compare$dataset, sex_compare$sex)
sex_tab
  chisq.test(sex_tab)

#family risk
u_grp <- unmerged %>%
  transmute(group, dataset = "unmerged")

m_grp <- merged %>%
  transmute(group, dataset = "merged")

grp_compare <- bind_rows(u_grp, m_grp)

grp_tab <- table(grp_compare$dataset, grp_compare$group)
grp_tab2 <- grp_tab[, c("Control", "MDD Risk", "BD Risk")]
grp_tab2
chisq.test(grp_tab2)


#age
age1 <- as.numeric(unmerged$age)
age2 <- as.numeric(merged$age)

t.test(age1, age2)

mean(age1)
mean(age2)
sd(age1)
sd(age2)
```


#Demographics
```{r}
merged$age <- as.numeric(merged$age)
merged$time_point <- as.numeric(merged$time_point)


race_lookup <- FOR %>%
  filter(!is.na(race)) %>%
  group_by(Subject_ID) %>%
  summarise(
    race = first(race),   # or use most frequent if messy
    .groups = "drop"
  )


merged_s <- merged 
merged_s <- merged_s %>%
  left_join(race_lookup, by = "Subject_ID")
library(dplyr)
library(tibble)

# 1) One row per Subject_ID (edit race column name if needed)
demo <- merged_s %>%
  group_by(Subject_ID) %>%
  summarise(
    group = first(group1),
    age   = mean(age, na.rm = TRUE),
    sex   = first(sex),
    race  = first(race.y),
    .groups = "drop"
  ) %>%
  mutate(
    group = factor(group,
                   levels = c(0, 1, 2, 3, 4),
                   labels = c("Control", "MDD Risk", "BD Risk", "Psy Risk", ""))
  )

demo_check <- demo %>%
  group_by(group) %>%
  summarise(
    n = n(),
    age_mean = mean(age, na.rm = TRUE),
    age_sd   = sd(age, na.rm = TRUE),

    female_n = sum(sex == 1, na.rm = TRUE),

    White_n  = sum(race == 1, na.rm = TRUE),
    Black_n  = sum(race == 2, na.rm = TRUE),
    Asian_n  = sum(race == 3, na.rm = TRUE),
    FirstNation_n = sum(race == 4, na.rm = TRUE),
    Other_n = sum(race %in% c(5,6, 9) | is.na(race), na.rm = TRUE),

    .groups = "drop"
  )


table_demo <- demo_check %>%
  pivot_longer(
    cols = -group,
    names_to = "Variable",
    values_to = "Value"
  ) %>%
  pivot_wider(
    names_from = group,
    values_from = Value
  )


pander(table_demo)



#Compare differences
#age
anova_age <- aov(age ~ group, data = demo)
summary(anova_age)

#sex
demo_chi <- demo %>%
  filter(group != "Psy Risk") %>%
  mutate(
    sex   = droplevels(factor(sex)),
    group = droplevels(factor(group))
  )

sex_tab <- table(demo_chi$group, demo_chi$sex)
sex_tab

chisq.test(sex_tab)

#race
demo <- demo %>%
  mutate(
    race = case_when(
      race %in% c("5", "6") ~ "9",
      TRUE                  ~ race
    )
  )
chisq.test(table(demo$group, demo$race))




```

#Apa talbe
```{r}
sex_test <- chisq.test(sex_tab)

sex_row <- tibble(
  Variable  = "Sex",
  Merged    = paste(sex_tab["merged", ], collapse = " / "),
  Unmerged  = paste(sex_tab["unmerged", ], collapse = " / "),
  Test      = "Chi-square",
  Statistic = sprintf("Ï‡Â²(%d) = %.2f", sex_test$parameter, sex_test$statistic),
  p_value   = sex_test$p.value
)

grp_test <- chisq.test(grp_tab2)

grp_row <- tibble(
  Variable  = "Familial risk group",
  Merged    = paste(grp_tab2["merged", ], collapse = " / "),
  Unmerged  = paste(grp_tab2["unmerged", ], collapse = " / "),
  Test      = "Chi-square",
  Statistic = sprintf("Ï‡Â²(%d) = %.2f", grp_test$parameter, grp_test$statistic),
  p_value   = grp_test$p.value
)


age_test <- t.test(age1, age2)

age_row <- tibble(
  Variable  = "Age (years)",
  Merged    = sprintf("%.2f (%.2f)", mean(age2, na.rm = TRUE), sd(age2, na.rm = TRUE)),
  Unmerged  = sprintf("%.2f (%.2f)", mean(age1, na.rm = TRUE), sd(age1, na.rm = TRUE)),
  Test      = "t-test",
  Statistic = sprintf("t(%.1f) = %.2f", age_test$parameter, age_test$statistic),
  p_value   = age_test$p.value
)


supp_table <- bind_rows(sex_row, grp_row, age_row) %>%
  mutate(
    p_value = ifelse(p_value < .001, "< .001", sprintf("%.3f", p_value))
  )

supp_table
library(flextable)

apa_table <- flextable(supp_table) %>%
  set_header_labels(
    Variable  = "Variable",
    Merged    = "Merged sample",
    Unmerged  = "Unmerged sample",
    Test      = "Test",
    Statistic = "Statistic",
    p_value   = "p"
  ) %>%
  autofit() %>%
  theme_booktabs() %>%        # APA-style horizontal rules
  align(j = 2:6, align = "center", part = "all") %>%
  align(j = 1, align = "left", part = "all") %>%
  bold(j = 1, part = "body") %>%
  bold(part = "header") %>%
  set_caption(
    as_paragraph(
      as_chunk("Table S1\n", props = fp_text(font.size = 12, bold = TRUE)),
      as_chunk(
        "",
        props = fp_text(font.size = 12, italic = TRUE)
      )
    )
  )

apa_table

save_as_docx(
  apa_table,
  path = "Supplementary_Table_S1.docx"
)

```



